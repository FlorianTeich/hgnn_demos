{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src import utils, artificial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch_geometric\n",
    "from torch_geometric.explain import Explainer, GNNExplainer, CaptumExplainer\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from random import choice, seed\n",
    "from typing import Dict\n",
    "import kuzu\n",
    "import pathlib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from torch_geometric.nn import (MLP, BatchNorm, GraphConv, MultiAggregation,\n",
    "                                SAGEConv, to_hetero)\n",
    "from torch_geometric.nn import (MLP, BatchNorm, LayerNorm, GraphConv, MultiAggregation,\n",
    "                                    SAGEConv, to_hetero)\n",
    "\n",
    "db = kuzu.Database(str(os.path.abspath(\"\")) + \"/../data/demo\")\n",
    "persons = pd.read_parquet(str(os.path.abspath(\"\")) + \"/../data/persons.parquet\")\n",
    "train_inds = torch.tensor(persons[persons[\"mode\"] == \"train\"].index.tolist(), dtype=torch.long)\n",
    "test_inds = torch.tensor(persons[persons[\"mode\"] == \"test\"].index.tolist(), dtype=torch.long)\n",
    "train_loader, test_loader = utils.get_loaders(db, 1, train_inds, test_inds)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_data = pd.read_parquet(str(os.path.abspath(\"\")) + \"/../data/diagnoses.parquet\")\n",
    "drug_data = pd.read_parquet(str(os.path.abspath(\"\")) + \"/../data/drugs.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its = iter(test_loader)\n",
    "batch = next(its)\n",
    "\n",
    "aggr = \"max\"\n",
    "\n",
    "batch = batch.to(device)\n",
    "metadata = batch.metadata()\n",
    "\n",
    "model = utils.GraphLevelGNN()\n",
    "model = to_hetero(model, metadata, aggr=aggr, debug=True).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(str(os.path.abspath(\"\")) + \"/../models/checkpoint.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# networkx-viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"person\"].y.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(its)\n",
    "\n",
    "while batch[\"person\"].y.item() != 1.0:\n",
    "    batch = next(its)\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    ),\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    #threshold_config=dict(\n",
    "    #    #threshold_type='topk',\n",
    "    #    threshold_type='topk',\n",
    "    #    value=200,\n",
    "    #),\n",
    ")\n",
    "\n",
    "btch = batch.to(device)\n",
    "\n",
    "explanation = explainer(\n",
    "    btch.x_dict,\n",
    "    btch.edge_index_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "btch_ = copy.copy(btch)\n",
    "\n",
    "ents = list(btch_.__dict__[\"_node_store_dict\"].keys())\n",
    "for entity in ents:\n",
    "    btch_[entity][\"node_mask\"] = explanation[entity][\"node_mask\"]\n",
    "\n",
    "ents = list(btch_.__dict__[\"_edge_store_dict\"].keys()) \n",
    "for entity in ents:\n",
    "    btch_[entity][\"edge_mask\"] = explanation[entity][\"edge_mask\"]\n",
    "    \n",
    "btch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Mapping from id to specific node inside heterogeneous graph\n",
    "node_ents = sorted(list(btch_.__dict__[\"_node_store_dict\"].keys()))\n",
    "edge_ents = sorted(list(btch_.__dict__[\"_edge_store_dict\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#btch_[\"drug\"][\"node_mask\"] = (btch_[\"drug\"][\"node_mask\"].abs().sum(axis=1)).log()\n",
    "#btch_[\"person\"][\"node_mask\"] = (btch_[\"person\"][\"node_mask\"].abs().sum(axis=1)).log()\n",
    "#btch_[\"diagnosis\"][\"node_mask\"] = (btch_[\"diagnosis\"][\"node_mask\"].abs().sum(axis=1)).log()\n",
    "\n",
    "btch_[\"drug\"][\"node_mask\"] = (btch_[\"drug\"][\"node_mask\"].abs().sum(axis=1)).log()\n",
    "btch_[\"person\"][\"node_mask\"] = (btch_[\"person\"][\"node_mask\"].abs().sum(axis=1)).log()\n",
    "btch_[\"diagnosis\"][\"node_mask\"] = (btch_[\"diagnosis\"][\"node_mask\"].abs().sum(axis=1)).log()\n",
    "homo_batch = btch_.to_homogeneous(node_attrs=[\"node_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch_geometric.utils.to_networkx(homo_batch, node_attrs=[\"node_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.set_node_attributes(g, torch.tensor([g.nodes[n]['node_mask'] for n in g.nodes]).softmax(0).tolist(), \"node_mask\")\n",
    "\n",
    "for i, e in enumerate(torch.tensor([g.nodes[n]['node_mask'] for n in g.nodes]).softmax(0).tolist()):\n",
    "    g.nodes[i]['node_mask'] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[g.nodes[n]['node_mask'] for n in g.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.Figure()\n",
    "pos = nx.spring_layout(g)\n",
    "ec = nx.draw_networkx_edges(g, pos, alpha=0.2)\n",
    "nc = nx.draw_networkx_nodes(g, pos, node_color=[g.nodes[n]['node_mask'] for n in g.nodes], node_size=800, cmap=plt.cm.Blues, edgecolors=\"k\", vmin=0.0,)\n",
    "plt.colorbar(nc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_batch = batch.to_homogeneous(node_attrs=[\"node_mask\"])\n",
    "g = torch_geometric.utils.to_networkx(homo_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(list(range(btch_.num_nodes)))\n",
    "\n",
    "options = {\"edgecolors\": \"tab:gray\", \"node_size\": 800, \"alpha\": 0.9}\n",
    "nx.draw_networkx_nodes(G, nodelist=[0, 1, 2, 3], node_color=\"tab:red\", **options)\n",
    "nx.draw_networkx_nodes(G, nodelist=[4, 5, 6, 7], node_color=\"tab:blue\", **options)\n",
    "\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "its = iter(test_loader)\n",
    "batch = next(its)\n",
    "batch = next(its)\n",
    "\n",
    "homo_batch = batch.to_homogeneous()\n",
    "g = torch_geometric.utils.to_networkx(homo_batch)\n",
    "\n",
    "w = GraphWidget(graph=g)\n",
    "\n",
    "def custom_color_mapping(index: int, node: Dict):\n",
    "    \"\"\"throw some hex numbers together\"\"\"\n",
    "    return \"#\"+''.join([choice('0123456789abcdef') for j in range(6)])\n",
    "\n",
    "def custom_color_mapping2(index: int, node: Dict):\n",
    "    \"\"\"throw some hex numbers together\"\"\"\n",
    "    colors = [\"#ff0000\", \"#00ff00\", \"#0000ff\"]\n",
    "    return colors[homo_batch[\"node_type\"][index]]\n",
    "\n",
    "w.set_node_color_mapping(custom_color_mapping2)\n",
    "\n",
    "res = pd.DataFrame({\"text\": [i for i in string.ascii_letters[:26]]})\n",
    "restable = utils.encode_strings(res[\"text\"])\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    ),\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    threshold_config=dict(\n",
    "        threshold_type='topk',\n",
    "        value=200,\n",
    "    ),\n",
    ")\n",
    "\n",
    "btch = batch.to(device)\n",
    "\n",
    "explanation = explainer(\n",
    "    btch.x_dict,\n",
    "    btch.edge_index_dict,\n",
    ")\n",
    "\n",
    "# Create Labels\n",
    "labels = []\n",
    "for i in set(homo_batch[\"node_type\"].tolist()):\n",
    "    if (homo_batch[\"node_type\"] == i).sum().item() == 1:\n",
    "        labels.append(\"PID\")\n",
    "    else:\n",
    "        if len(drug_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"PID\"].unique()) == 1:\n",
    "            a = drug_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"drug_short\"].values.tolist()\n",
    "            b = drug_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"drug_age\"].values.tolist()\n",
    "            tmplabels = [\"drug: \" + j + \" \" + k[0] for j,k in zip(a, [str(c) for c in b])]\n",
    "            labels.extend(tmplabels)\n",
    "        elif len(diagnosis_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"PID\"].unique()) == 1:\n",
    "            a = diagnosis_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"diagnosis_short\"].values.tolist()\n",
    "            b = diagnosis_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"diagnosis_age\"].values.tolist()\n",
    "            tmplabels = [\"diagnosis: \" + j + \" \" + k[0] for j,k in zip(a, [str(c) for c in b])]\n",
    "            labels.extend(tmplabels)\n",
    "\n",
    "def labels_func(index: int, node: Dict):\n",
    "    return labels[index]\n",
    "\n",
    "w.set_node_label_mapping(labels_func)\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = GraphWidget(graph=g)\n",
    "\n",
    "def custom_color_mapping(index: int, node: Dict):\n",
    "    \"\"\"throw some hex numbers together\"\"\"\n",
    "    return \"#\"+''.join([choice('0123456789abcdef') for j in range(6)])\n",
    "\n",
    "def custom_color_mapping3(index: int, node: Dict):\n",
    "    \"\"\"throw some hex numbers together\"\"\"\n",
    "    # Get number of nodes per nodetype\n",
    "    print(node)\n",
    "    max_val = 16.0\n",
    "    if homo_batch[\"node_type\"][index] == 0:\n",
    "        scalar = explanation[\"drug\"][\"node_mask\"][index - 0].abs().sum().item() / max_val\n",
    "    elif homo_batch[\"node_type\"][index] == 1:\n",
    "        scalar = explanation[\"diagnosis\"][\"node_mask\"][index - 12].abs().sum().item() / max_val\n",
    "    elif homo_batch[\"node_type\"][index] == 2:\n",
    "        scalar = explanation[\"person\"][\"node_mask\"][index - 22].abs().sum().item() / max_val\n",
    "    \n",
    "    scalar = max(0, scalar)\n",
    "    scalar = min(255, scalar)\n",
    "    return '#ff' + ('%02x' % (255 - int(scalar * 255))) + ('%02x' % (255 - int(scalar * 255)))\n",
    "\n",
    "w.set_node_color_mapping(custom_color_mapping3)\n",
    "\n",
    "# Create Labels\n",
    "labels = []\n",
    "for i in set(homo_batch[\"node_type\"].tolist()):\n",
    "    if (homo_batch[\"node_type\"] == i).sum().item() == 1:\n",
    "        labels.append(\"KVNR\")\n",
    "    else:\n",
    "        if len(drug_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"PID\"].unique()) == 1:\n",
    "            a = drug_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"drug_short\"].values.tolist()\n",
    "            b = drug_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"drug_age\"].values.tolist()\n",
    "            tmplabels = [\"drug: \" + j + \" \" + k[0] for j,k in zip(a, [str(c) for c in b])]\n",
    "            labels.extend(tmplabels)\n",
    "        elif len(diagnosis_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"PID\"].unique()) == 1:\n",
    "            a = diagnosis_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"diagnosis_short\"].values.tolist()\n",
    "            b = diagnosis_data.iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == i].tolist()][\"diagnosis_age\"].values.tolist()\n",
    "            tmplabels = [\"diagnosis: \" + j + \" \" + k[0] for j,k in zip(a, [str(c) for c in b])]\n",
    "            labels.extend(tmplabels)\n",
    "\n",
    "def labels_func(index: int, node: Dict):\n",
    "    return labels[index]\n",
    "\n",
    "w.set_node_label_mapping(labels_func)\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project': 'demo'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "with open('../default.yml') as f:\n",
    "    data = yaml.load(f, Loader=SafeLoader)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgnn_demos-1xirZSoL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
