{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils\n",
    "import artificial_data\n",
    "\n",
    "os.chdir(\"./../\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch_geometric\n",
    "from torch_geometric.explain import Explainer, GNNExplainer, CaptumExplainer\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from random import choice, seed\n",
    "from typing import Dict\n",
    "import kuzu\n",
    "import pathlib\n",
    "import torch\n",
    "import pandas as pd\n",
    "import string\n",
    "from utils import load_yaml\n",
    "\n",
    "\n",
    "config = load_yaml(\"./default.yml\")\n",
    "\n",
    "backend_data = dict()\n",
    "backend_id = dict()\n",
    "\n",
    "for nodetype in config[\"nodes\"]:\n",
    "    backend_data[nodetype[\"name\"]] = pd.read_parquet(nodetype[\"file\"])\n",
    "    backend_id[nodetype[\"name\"]] = nodetype[\"key\"]\n",
    "\n",
    "db = kuzu.Database(str(os.path.abspath(\"\")) + \"/data/demo\")\n",
    "\n",
    "train_inds = torch.tensor(pd.read_parquet(config[\"task\"][\"train_inds\"])[\"ids\"].values, dtype=torch.long)\n",
    "test_inds = torch.tensor(pd.read_parquet(config[\"task\"][\"test_inds\"])[\"ids\"].values, dtype=torch.long)\n",
    "\n",
    "train_loader, test_loader = utils.get_loaders(db, 1, train_inds, test_inds, config[\"task\"][\"target_entity\"])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import to_hetero\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "its = iter(test_loader)\n",
    "batch = next(its)\n",
    "\n",
    "batch = batch.to(device)\n",
    "metadata = batch.metadata()\n",
    "\n",
    "module = __import__(config[\"script\"])\n",
    "mdl = getattr(module, config[\"task\"][\"model\"])\n",
    "margs = config[\"task\"][\"model_args\"]\n",
    "hmargs = config[\"task\"][\"heteromodel_args\"]\n",
    "model = mdl(**margs)\n",
    "model = to_hetero(model, metadata, **hmargs).to(device)\n",
    "\n",
    "opt = getattr(optim, config[\"task\"][\"optimizer\"])\n",
    "oargs = config[\"task\"][\"optimizer_args\"]\n",
    "optimizer = opt(model.parameters(), **oargs)\n",
    "\n",
    "model.load_state_dict(torch.load(str(os.path.abspath(\"\")) + \"/models/checkpoint.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_explanation():\n",
    "    batch = next(its)\n",
    "\n",
    "    while batch[\"person\"].y.item() != 1.0:\n",
    "        batch = next(its)\n",
    "\n",
    "    explainer = Explainer(\n",
    "        model=model,\n",
    "        algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "        explanation_type='model',\n",
    "        model_config=dict(\n",
    "            mode='multiclass_classification',\n",
    "            task_level='graph',\n",
    "            return_type='raw',\n",
    "        ),\n",
    "        node_mask_type='attributes',\n",
    "        edge_mask_type='object',\n",
    "    )\n",
    "\n",
    "    btch = batch.to(device)\n",
    "\n",
    "    explanation = explainer(\n",
    "        btch.x_dict,\n",
    "        btch.edge_index_dict,\n",
    "    )\n",
    "\n",
    "    btch_ = copy.copy(btch)\n",
    "\n",
    "    ents = list(btch_.__dict__[\"_node_store_dict\"].keys())\n",
    "    for entity in ents:\n",
    "        btch_[entity][\"node_mask\"] = explanation[entity][\"node_mask\"]\n",
    "\n",
    "    ents = list(btch_.__dict__[\"_edge_store_dict\"].keys()) \n",
    "    for entity in ents:\n",
    "        btch_[entity][\"edge_mask\"] = explanation[entity][\"edge_mask\"]\n",
    "        \n",
    "    for nodetype in config[\"nodes\"]:\n",
    "        btch_[nodetype[\"name\"]][\"node_mask\"] = (btch_[nodetype[\"name\"]][\"node_mask\"].abs().sum(axis=1)).log()\n",
    "    \n",
    "    homo_batch = btch_.to_homogeneous(node_attrs=[\"node_mask\"])\n",
    "    g = torch_geometric.utils.to_networkx(homo_batch, node_attrs=[\"node_mask\"])\n",
    "\n",
    "    for i, e in enumerate(torch.tensor([g.nodes[n]['node_mask'] for n in g.nodes]).softmax(0).tolist()):\n",
    "        g.nodes[i]['node_mask'] = e\n",
    "\n",
    "    plt.Figure()\n",
    "    pos = nx.spring_layout(g)\n",
    "    ec = nx.draw_networkx_edges(g, pos, alpha=0.2)\n",
    "    nc = nx.draw_networkx_nodes(g, pos, node_color=[g.nodes[n]['node_mask'] for n in g.nodes], node_size=800, cmap=plt.cm.Blues, edgecolors=\"k\", vmin=0.0,)\n",
    "    plt.colorbar(nc)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_explanation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(its)\n",
    "\n",
    "while batch[\"person\"].y.item() != 1.0:\n",
    "    batch = next(its)\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer('IntegratedGradients'),\n",
    "    explanation_type='model',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='graph',\n",
    "        return_type='raw',\n",
    "    ),\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    ")\n",
    "\n",
    "btch = batch.to(device)\n",
    "\n",
    "explanation = explainer(\n",
    "    btch.x_dict,\n",
    "    btch.edge_index_dict,\n",
    ")\n",
    "\n",
    "btch_ = copy.copy(btch)\n",
    "\n",
    "ents = list(btch_.__dict__[\"_node_store_dict\"].keys())\n",
    "for entity in ents:\n",
    "    btch_[entity][\"node_mask\"] = explanation[entity][\"node_mask\"]\n",
    "\n",
    "ents = list(btch_.__dict__[\"_edge_store_dict\"].keys()) \n",
    "for entity in ents:\n",
    "    btch_[entity][\"edge_mask\"] = explanation[entity][\"edge_mask\"]\n",
    "    \n",
    "for nodetype in config[\"nodes\"]:\n",
    "    btch_[nodetype[\"name\"]][\"node_mask\"] = (btch_[nodetype[\"name\"]][\"node_mask\"].abs().sum(axis=1)).log()\n",
    "\n",
    "homo_batch = btch_.to_homogeneous(node_attrs=[\"node_mask\", \"id\"])\n",
    "g = torch_geometric.utils.to_networkx(homo_batch, node_attrs=[\"node_mask\"])\n",
    "\n",
    "for i, e in enumerate(torch.tensor([g.nodes[n]['node_mask'] for n in g.nodes]).softmax(0).tolist()):\n",
    "    g.nodes[i]['node_mask'] = e\n",
    "\n",
    "#labels = dict(enumerate(homo_batch[\"node_type\"].tolist()))\n",
    "\n",
    "labels = []\n",
    "for t in sorted(list(set(homo_batch[\"node_type\"].tolist()))):\n",
    "    labels.extend(backend_data[homo_batch._node_type_names[t]].iloc[homo_batch[\"id\"][homo_batch[\"node_type\"] == t].tolist()][backend_id[homo_batch._node_type_names[t]]].values.tolist())\n",
    "\n",
    "labels = dict(enumerate(labels))\n",
    "\n",
    "plt.Figure()\n",
    "pos = nx.spring_layout(g)\n",
    "ec = nx.draw_networkx_edges(g, pos, alpha=0.2)\n",
    "nc = nx.draw_networkx_nodes(g, pos, node_color=[g.nodes[n]['node_mask'] for n in g.nodes], node_size=800, cmap=plt.cm.Blues, edgecolors=\"k\", vmin=0.0,)\n",
    "la = nx.draw_networkx_labels(g, pos, labels)\n",
    "plt.colorbar(nc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_batch._node_type_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgnn_demos-1xirZSoL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
